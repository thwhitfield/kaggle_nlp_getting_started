{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype end to end process\n",
    "1. Save the train/val/test sets (which were generated from the train set)\n",
    "2. Then have a simple process to train on the train set, optimize on the val set, and then test on the holdout test set. I'll then test the outputs on the actual submission test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trav_nlp.misc import polars_train_val_test_split\n",
    "from trav_lib.evaluate import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.create({\n",
    "    'raw_data': {\n",
    "        'train_path': '../data/train.csv',\n",
    "        'test_path': '../data/test.csv',\n",
    "        'sample_submission_path': '../data/sample_submission.csv',\n",
    "    },\n",
    "    # Split the train dataset into a train/val/test split\n",
    "    'training_data': {\n",
    "        'train_path': '../data/splits/train.parquet',\n",
    "        'val_path': '../data/splits/val.parquet',\n",
    "        'test_path': '../data/splits/test.parquet'\n",
    "    },\n",
    "\n",
    "    'params': {\n",
    "        'train_frac': 0.8,\n",
    "        'val_frac': 0.1,\n",
    "        'test_frac': 0.1,\n",
    "        'train_val_test_seed': 42,   \n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the train/val/test splits if they don't already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_create_data(cfg):\n",
    "\n",
    "    # Define local variables for configuration paths\n",
    "    train_path = cfg.training_data.train_path\n",
    "    val_path = cfg.training_data.val_path\n",
    "    test_path = cfg.training_data.test_path\n",
    "    raw_train_path = cfg.raw_data.train_path\n",
    "\n",
    "    # Define local variables for parameters\n",
    "    train_frac = cfg.params.train_frac\n",
    "    val_frac = cfg.params.val_frac\n",
    "    test_frac = cfg.params.test_frac\n",
    "    seed = cfg.params.train_val_test_seed\n",
    "\n",
    "    if Path(train_path).exists():\n",
    "        df_train = pl.read_parquet(train_path)\n",
    "        df_val = pl.read_parquet(val_path)\n",
    "        df_test = pl.read_parquet(test_path)\n",
    "    else:\n",
    "        df = pl.read_csv(raw_train_path)\n",
    "        Path(train_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        df_train, df_val, df_test = polars_train_val_test_split(\n",
    "            df, \n",
    "            train_frac=train_frac,\n",
    "            val_frac=val_frac,\n",
    "            test_frac=test_frac,\n",
    "            shuffle=True,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "        df_train.write_parquet(train_path)\n",
    "        df_val.write_parquet(val_path)\n",
    "        df_test.write_parquet(test_path)\n",
    "    \n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = load_or_create_data(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>keyword</th><th>location</th><th>text</th><th>target</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>9853</td><td>&quot;trauma&quot;</td><td>null</td><td>&quot;Today was trauma on top of tra…</td><td>0</td></tr><tr><td>798</td><td>&quot;battle&quot;</td><td>null</td><td>&quot;Dragon Ball Z: Battle Of Gods …</td><td>0</td></tr><tr><td>9822</td><td>&quot;trauma&quot;</td><td>null</td><td>&quot;Hiroshima: They told me to pai…</td><td>1</td></tr><tr><td>1817</td><td>&quot;buildings%20on%20fire&quot;</td><td>&quot;New Hampshire&quot;</td><td>&quot;17 people displaced after 3-al…</td><td>1</td></tr><tr><td>6148</td><td>&quot;hijack&quot;</td><td>&quot;Nigeria&quot;</td><td>&quot;Criminals Who Hijack Lorries A…</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────┬───────────────────────┬───────────────┬─────────────────────────────────┬────────┐\n",
       "│ id   ┆ keyword               ┆ location      ┆ text                            ┆ target │\n",
       "│ ---  ┆ ---                   ┆ ---           ┆ ---                             ┆ ---    │\n",
       "│ i64  ┆ str                   ┆ str           ┆ str                             ┆ i64    │\n",
       "╞══════╪═══════════════════════╪═══════════════╪═════════════════════════════════╪════════╡\n",
       "│ 9853 ┆ trauma                ┆ null          ┆ Today was trauma on top of tra… ┆ 0      │\n",
       "│ 798  ┆ battle                ┆ null          ┆ Dragon Ball Z: Battle Of Gods … ┆ 0      │\n",
       "│ 9822 ┆ trauma                ┆ null          ┆ Hiroshima: They told me to pai… ┆ 1      │\n",
       "│ 1817 ┆ buildings%20on%20fire ┆ New Hampshire ┆ 17 people displaced after 3-al… ┆ 1      │\n",
       "│ 6148 ┆ hijack                ┆ Nigeria       ┆ Criminals Who Hijack Lorries A… ┆ 1      │\n",
       "└──────┴───────────────────────┴───────────────┴─────────────────────────────────┴────────┘"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, I guess I'll have a large wrapper function which runs a single experiment\n",
    "1. I suppose the larger wrapper will be run_experiment() or something similar. Then within that run_experiment wrapper I can have various different types of pipelines to train and evaluate, etc.\n",
    "2. I'll start with the most simple pipeline I can do. An sklearn pipeline\n",
    "3. The general idea of this will be to run an experiment, get the results of the model experiment, at the very least on the hold out test set, and then also submit the results to kaggle and get the results of that submission as well.\n",
    "    - So, it'll be train, val, and hold-out test set performance in a chart. Then also I'll submit the kaggle and get that performance.\n",
    "4. So first I'll code up the various parts of the loop. \n",
    "5. Then I'll integrate MLFlow so that I can include all those results into a single chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trav_nlp.misc import submit_to_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "import logging\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"X does not have valid feature names, but LGBMClassifier was fitted with feature names\",\n",
    "    category=UserWarning,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 10:06:12 INFO: Logging is configured.\n"
     ]
    }
   ],
   "source": [
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s %(levelname)s: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    \n",
    "# Usage example:\n",
    "setup_logging()\n",
    "logging.info(\"Logging is configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train, df_val = None):\n",
    "    \"\"\"Train and optimize the model\"\"\"\n",
    "\n",
    "    # Define a function to extract the 'text' column\n",
    "    def extract_text(df):\n",
    "        return df['text']\n",
    "\n",
    "    def convert_to_numpy(scipy_csr_matrix):\n",
    "        return scipy_csr_matrix.toarray()\n",
    "\n",
    "    # Create a FunctionTransformer to apply that function\n",
    "    extract_text_transform = FunctionTransformer(extract_text)\n",
    "\n",
    "    convert_to_numpy_transform = FunctionTransformer(convert_to_numpy)\n",
    "\n",
    "    # Create the pipeline with the text selector, vectorizer, and classifier\n",
    "    pipeline = make_pipeline(\n",
    "        extract_text_transform,\n",
    "        CountVectorizer(),\n",
    "        convert_to_numpy_transform,\n",
    "        lgb.LGBMClassifier(random_state=42)\n",
    "    )\n",
    "\n",
    "    pipeline.fit(df_train, df_train['target'])\n",
    "\n",
    "    train_preds = pipeline.predict_proba(df_train)[:,1]\n",
    "    train_roc_auc = roc_auc_score(df_train['target'], train_preds)\n",
    "    logging.info(f\"Train ROC: {train_roc_auc}\")\n",
    "\n",
    "    if df_val is not None:\n",
    "        val_preds = pipeline.predict_proba(df_val)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(df_val['target'], val_preds)\n",
    "        logging.info(f\"Val ROC: {val_roc_auc}\")\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 2614, number of negative: 3476\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1843\n",
      "[LightGBM] [Info] Number of data points in the train set: 6090, number of used features: 699\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.429228 -> initscore=-0.285001\n",
      "[LightGBM] [Info] Start training from score -0.285001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 13:03:15 INFO: Train ROC: 0.9263938401965869\n",
      "2025-02-22 13:03:15 INFO: Val ROC: 0.8571826280623607\n"
     ]
    }
   ],
   "source": [
    "pipeline = train(df_train, df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 13:06:53 INFO: Test ROC: 0.8419177701317206\n"
     ]
    }
   ],
   "source": [
    "def eval_df_test(pipeline, df_test):\n",
    "\n",
    "    test_preds = pipeline.predict_proba(df_test)[:, 1]\n",
    "    test_roc_auc = roc_auc_score(df_test['target'], test_preds)\n",
    "    logging.info(f\"Test ROC: {test_roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_submit_to_kaggle(pipeline, kaggle_test_path, kaggle_sample_submission_path):\n",
    "\n",
    "    df_kaggle_test = pl.read_csv(kaggle_test_path)\n",
    "    kaggle_sample_submission = pl.read_csv(kaggle_sample_submission_path)\n",
    "\n",
    "    kaggle_test_preds = pipeline.predict(df_kaggle_test)\n",
    "    kaggle_sample_submission = kaggle_sample_submission.with_columns(\n",
    "        pl.Series(\"target\", kaggle_test_preds)\n",
    "    )\n",
    "\n",
    "    submissions_dir = Path('../data/submissions')\n",
    "    timestamp = datetime.datetime.now().strftime('%Y_%m_%d__%H_%M_%S')\n",
    "    filename = f\"submission_{timestamp}.csv\"\n",
    "    submission_path = submissions_dir / filename\n",
    "\n",
    "    kaggle_sample_submission.write_csv(submission_path)\n",
    "\n",
    "    submit_to_kaggle('nlp-getting-started', submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(cfg, run_submit_to_kaggle = False):\n",
    "    \"\"\"Train/optimize a model, and then report the results of the model training run. \n",
    "    Also save/return the scores on the test.csv file for submission to kaggle if the model\n",
    "    appears to perform well.\n",
    "\n",
    "    So I'll have a train_model function\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    df_train, df_val, df_test = load_or_create_data(cfg)\n",
    "\n",
    "    pipeline = train(df_train, df_val)\n",
    "\n",
    "    eval_df_test(pipeline, df_test)\n",
    "\n",
    "    if run_submit_to_kaggle:\n",
    "        df_full_train = pl.concat([df_train, df_val, df_test])\n",
    "        full_pipeline = train(df_full_train)\n",
    "        generate_and_submit_to_kaggle(full_pipeline, cfg.raw_data.test_path, cfg.raw_data.sample_submission_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_nlp_getting_started",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
